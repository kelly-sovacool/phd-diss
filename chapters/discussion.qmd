```{r mikropml_downloads}
schtools::set_knitr_opts()
library(cranlogs)
library(dplyr)
cran_downloads <- cran_downloads(package = "mikropml", 
                                 from = "2020-11-23", to = "2023-06-08") %>% 
  pull(count) %>% sum()
conda_downloads <- 24727
```

# Discussion

## Major contributions

This dissertation introduces two new tools that improve ML capabilities for
microbiome research and beyond, applies ML with microbiome data to CDI severity
prediction, and introduces two new educational resources that teach coding for
data science to young audiences and scientists.
For all of the analyses described in this dissertation, the complete software
workflows and dependencies required to reproduce the results are publicly
available with open source licenses so that anyone can reproduce, replicate, or
build upon our work.
The impact of this work spans microbial ecology, gut microbiome research,
applied machine learning, and data science education.

### Novel method for reference-based OTU clustering

OptiFit is a novel OTU clustering method that enables high quality OTUs for ML
workflows and other applications where consistent OTUs are required.
Prior to the development of OptiFit, the only option for researchers who wanted
to deploy OTU-based ML models was to cluster both the training set and external
validation sets to the same database using a closed-reference clustering method.
Existing tools for reference-based clustering against databases produce lower
quality OTUs than _de novo_ clustering with OptiClust.
However, _de novo_ clustering results in slightly different OTU assignments when
adding new sequences, thus models trained on one dataset could not be deployed
on new data due to incompatible features.
Now with OptiFit, an initial dataset can be clustered _de novo_ with OptiClust
and then used to train a model, then new sequences from an external validation
set can be fit to the OTUs from the training data prior to deploying the model
on the new dataset.
A follow-up paper demonstrated the suitability of OptiFit for this very task
on a colorectal cancer dataset to distinguish patients with screen-relevant 
neoplasias from normal controls [@armour_machine_2023].
OptiFit opens a new door for microbial ecologists to deploy ML models using
higher quality OTUs than were possible before.

### Microbiome models for prediction of severe CDI outcomes

Prior studies to date have trained models to predict severe CDI outcomes using
routine clinical data, selected serum biomarkers, curated variables from EHR
data, or entire EHRs.
However, none have focused on using the initial taxonomic composition of the gut
microbiome to predict CDI severity, despite ample evidence for a link between
dysbiosis and _C. difficile_ colonization, infection, and recurrence.
We trained models on OTU relative abundances collected on the day of CDI
diagnosis to predict four different definitions of severity.
Models trained to predict the pragmatic severity definition performed best, as
this definition uses as much data as possible while also using physicians'
determinations of whether severe outcomes were CDI-attributable when available.
While these models did not outperform prior EHR-based models extracted two days
after diagnosis, the pragmatic severity models matched the performance of
EHR-based models from the day of diagnosis.
These results provide an initial exploration of the utility of OTU-based models
for predicting CDI severity, and they may become more clinically relevant in the
future as new evidence emerges of efficacious treatments for preventing severity.

### Educational resources

In Chapter 4.2, we introduced a new curriculum to teach introductory Python for
data science via live-coding or a flipped classroom format.
We deployed the curriculum for in-person and virtual Girls Who Code clubs during
a three year period with high school students as the audience.
The curriculum takes students from having no knowledge of programming to being
able to analyze a real-world dataset and present their findings to the group.
In a post-survey, students overwhelmingly reported that they improved their
Python programming skills, problem solving and critical thinking, collaboration
with others, and self-confidence.
Not only were the students we taught positively impacted; our curriculum is
free and available with an open source license so any other educators can use
our curriculum or modify it for their own needs.
This curriculum is continually improved upon and is still in use for the chapter
of Girls Who Code at the University of Michigan Department of Computational
Medicine and Bioinformatics.

In Chapter 4.3, we introduced a new curriculum to teach coding for reproducible
research practices to scientists and other researchers in an academic setting.
The Carpentries materials that inspired us taught three topics in a disparate
manner: introductory R programming, the Unix shell, and version control with
git and GitHub.
Our curriculum covers these topics in an integrated manner so that learners
understand how they are used together in practice.
We piloted the curriculum in a virtual workshop and assessed our work with a
post-workshop survey.
On average, learners reported that they felt more confident writing programs,
using programming to work with data, overcoming problems while programming, and
searching for answers to technical questions online.
This curriculum is still in use today for Carpentries workshops at the
University of Michigan and is freely available with an open source license for
anyone to use and modify.

### Software

In Chapter 4.4, we introduced a tool that integrates current best practices
for ML in a user-friendly R package.
Our goal was to enable researchers who are novices in ML to train and evaluate
models with guard rails to prevent common pitfalls, while allowing experienced
users to tailor the package for advanced needs.
At the time of this writing, mikropml has been downloaded `r cran_downloads`
times from the Comprehensive R Archive Network and `r conda_downloads` times
from the Anaconda package manager, suggesting a healthy user base.
The reach of mikropml has expanded outside of our immediate scientific network
and into fields spanning gut microbiome research, microbial ecology, public
health, and environmental research.
Rather than write code intended for one-time-use-only to conduct the ML analyses
we routinely perform, we chose to bundle our methods into a package for others
within and outside our lab to reuse for their own research.
As a result, our efforts have contributed directly to the greater scientific
endeavor, with 18 citations to date of the mikropml publication in the Journal
of Open Source Software.

In addition to mikropml, other software tools were developed while conducting
the research described in this dissertation.
These include: 
schtools, an R package for processing output from the mothur program and
miscellaneous functions for microbiome research [@sovacool_schtools_2022];
the mikropml snakemake workflow, a template for building reusable and scalable
machine learning pipelines with mikropml for use in high performance computing
environments [@sovacool_mikropml_2023],
and the mothur snakemake workflow, a template implementing the mothur MiSeq SOP
for processing 16S rRNA gene amplicon sequence data and authoring reproducible 
scientific manuscripts [@sovacool_mothur_2023].
While we have not published any stand-alone papers to describe these tools, they
have been used within the Schloss Lab for several manuscripts in process and
published work [@barron_intestinal_2022;@armour_machine_2023].

## Future work

Below, we discuss key areas of improvement and propose ideas to build on the
work described in Chapters 2 through 4.

### Integrate microbiota with clinical factors for improved CDI severity prediction

Our OTU-based models described in Chapter 3 were trained on a different dataset
as the EHR-based models we compared them to.
Since the different datasets have different proportions of severe cases,
precision and AUPRC are not directly comparable.
While AUROC has the same baseline regardless of the dataset and is thus always
directly comparable, it is not as useful for rare outcomes because the model
may identify many true negatives but few true positives and yet report a high
AUROC.
A more salient comparison would train models on the same cohort of patients
using either OTUs, EHRs, or both in order to determine which approach leads to
the best performance in terms of AUPRC.
However, to demonstrate clinical value, it is not enough to simply show that one
modeling approach outperforms another.
How a model might improve clinical practice if it were deployed must be
considered.
This especially relates to the treatment options available along with their
potential risks, which influences which performance metrics are most meaningful.
A large increase in AUROC, AUPRC, or other metrics may or may not translate to a
large increase in benefit to patients.
In situations where predicting a severe case may lead clinicians to choose a
treatment option that has an established record of safety, such as oral
fidaxomicin instead of vancomycin, false positives are tolerable and a lower
precision is acceptable.
On the other hand, if new evidence were to emerge of a treatment preventing
severe outcomes but with substantial risk of negative side effects, false
positives would be less acceptable and a higher precision would be required.
The ultimate goal of CDI severity prediction models is to help clinicians
identify early on which patients are at risk of experiencing a severe outcome
so they can tailor treatments to prevent the outcome from ever occurring, but
care must be taken to ensure no harm is inflicted on patients who never would
have experienced a severe outcome.

#### Decision curve analysis

For the analysis of potential clinical value, we reported the precision at the
95th percentile of risk, which is the decision threshold where 5% of cases are
predicted to be positive and would thus undergo a different treatment in order
to prevent the adverse outcome from occurring.
Choosing this threshold allowed for comparison to the previously published EHR
models which reported precision at that threshold.
However, rather than evaluating performance at a single threshold,
we could extend this across a range of thresholds.
Decision curve analysis would explore how the confusion matrix varies
across a range of thresholds for models of interest.
We could then compare the net benefit, NNS, or other metrics for different
modeling approaches, as their relative performance may vary across decision
thresholds.
A model based on only OTUs may perform optimally at a different threshold than
a model based on only EHRs, and different thresholds could be selected for model
deployment depending on the importance of recall versus precision for the
alternative treatment being considered by clinicians.

#### Cost-benefit analysis

The costs of model training, deployment, and treatment are significant factors
that influence the practicality of deploying models in clinical settings.
If a model has good discriminative performance, it may never be used if it is
expensive to collect the data for deployment.
Similarly, an inexpensive model may never be used if the alternative treatment
it would be paired with is too expensive.
We did not consider these costs when evaluating the potential clinical value,
although we reported the NNS and NNB when paired with the NNT of fidaxomicin so
the work could be extended to consider costs as well as other treatment options.
(For example, bezlotoxumab has also been shown to prevent recurrent CDI in
humans as well as systemic organ damage in mice
[@thandavaram_efficacy_2022;@mileto_bezlotoxumab_2022].
However, it is used as an adjuvant therapy and as such it does not replace
antibiotics for CDI treatment.)
A predictive model paired with a treatment may be cost-effective if the decrease
in costs for averting severe outcomes outweighs the increase in treatment costs
for cases predicted positive plus the costs of deployment, or if any increase in
cost is deemed worth the benefit [@kim_how_2021].
Since amplicon sequencing and data processing would need to be performed on CDI
patients in order to deploy an OTU-based model, while EHR-based models use
data that is already recorded, OTU-based models likely must far outperform
EHR-based models for the additional data collection to be cost-effective.
A limitation of cost-benefit analysis techniques is that the most often used
metric of benefit (Quality-Adjusted Life-Years) is controversial, as it is prone
to systematic bias and devalues health gains for patients with disabilities
[@kim_how_2021;@loomes_use_1989;@van_osch_correcting_2004;@disability_qaly_2019].
Although existing methodologies for cost-benefit analyses are imperfect,
performing a thorough cost-benefit analysis would provide more information about
whether deploying CDI severity prediction models could be worth the estimated
benefits gained.

### Beyond taxonomic composition

Efforts to find consistent changes in taxonomic composition of microbiomes
between normal and dysbiotic states have found mixed success, in part because
interpersonal variability in taxonomic composition sometimes exceeds the
variability between disease states.
ML models for diagnosing colorectal cancer or predicting severe CDI perform
moderately well, but may not perform well enough to justify clinical deployment.
Variability of microbiome composition between individuals with the same disease
status may be explained by functional redundancy, where different microbial
species carry out the same functions and thus can replace each other with
little effect on the overall function of the community [@louca_function_2018].
Extending analyses of taxonomic composition to also include the functional
composition of the microbiome may shed more light on how the microbiome changes
in disease states. 
Sequencing whole metagenomes to identify the genes present and annotate known
gene functions is commonly used to build a profile of functional potential of
the microbiome.
Functional potential could be paired with meta-transcriptomics or
untargeted mass spectrometry to validate the gene products that are activate in
a community, 
thus painting a more precise picture of active microbial functions than with
metagenomics alone.
Incorporating the known functional potential of the microbiome from metagenomic
data may help account for functional redundancy and improve the performance of
OTU-based models in classifying CRC, predicting CDI severity, or other 
microbiome modeling problems.
These insights could inform the design of future experiments to determine the
mechanisms of dysbiosis or improve performance of ML models for clinical
decision making.

### Continued maintenance of software tools and educational resources

It is notoriously difficult to fund the development and maintenance of
scientific software and educational resources.
Nevertheless, we initially developed and continue to maintain the open source
contributions described in Chapter 4 with our discretionary time because we
believe they are valuable to the scientific community and society at large.
Developing software and educational resources is never a one-and-done task; they
must be maintained as users discover and report bugs, new methods are
discovered, and the preferences of the community change over time.
While no tool is designed to be used forever (despite the best intentions of
fans of _certain_ programming languages), neglecting to maintain a tool will
unnecessarily hasten its obsolescence.
We would much prefer to honor the time and effort spent during initial
development, as well as that of end-users who adopt our tools and resources, by
continuing to maintain them.
However, few funding mechanisms through traditional grant-making agencies exist
to maintain existing resources, as most value new discoveries and ideas.
We are hopeful that the landscape is changing for the better with the
announcement of programs such as the Better Software for Science initiative by
the Alfred P. Sloan Foundation [@sloan-better-software].
Funding mechanisms like these will enable scientists and researchers to not only
create new tools and resources but also maintain them over time, so that the
time, effort, and other resources expended in creating and adopting them are
used efficiently.

## Conclusions

In this work, we introduced a novel method for OTU clustering that improves the
ability of researchers to apply ML to microbiome research,
applied ML to predict the severity of CDI infections from the composition of the 
gut microbiome,
and introduced three new resources that empower data scientists from a broad
range of backgrounds to go from coding novices to ML practitioners.
This dissertation advances bioinformatics for microbiome research
from the start of the data analysis pipeline through applying machine learning
to biological and clinical problems, and ultimately toward enabling other
scientists to reproduce, replicate, and build upon our work.
