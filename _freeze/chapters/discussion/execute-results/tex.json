{
  "hash": "070474fb8598db8fd7e40081b4be54ae",
  "result": {
    "markdown": "::: {.cell}\n\n:::\n\n\n# Discussion\n\n## Major contributions\n\nThis dissertation introduces two new tools that improve ML capabilities for\nmicrobiome research and beyond, applies ML with microbiome data to CDI severity\nprediction, and introduces two new educational resources that teach coding for\ndata science to young audiences and scientists.\nFor all of the analyses described in this dissertation, the complete software\nworkflows and dependencies required to reproduce the results are publicly\navailable with open source licenses so that anyone can reproduce, replicate, or\nbuild upon our work.\nThe impact of this work spans microbial ecology, gut microbiome research,\napplied machine learning, and data science education.\n\n### Novel method for reference-based OTU clustering\n\nOptiFit is a novel OTU clustering method that enables high quality OTUs for ML\nworkflows and other applications where consistent OTUs are required.\nPrior to the development of OptiFit, the only option for researchers who wanted\nto deploy OTU-based ML models was to cluster both the training set and external\nvalidation sets to the same database using a closed-reference clustering method.\nExisting tools for reference-based clustering against databases produce lower\nquality OTUs than _de novo_ clustering with OptiClust.\nHowever, _de novo_ clustering results in slightly different OTU assignments when\nadding new sequences, thus models trained on one dataset could not be deployed\non new data due to incompatible features.\nNow with OptiFit, an initial dataset can be clustered _de novo_ with OptiClust\nand then used to train a model, then new sequences from an external validation\nset can be fit to the OTUs from the training data prior to deploying the model\non the new dataset.\nA follow-up paper demonstrated the suitability of OptiFit for this very task\non a colorectal cancer dataset to distinguish patients with screen-relevant \nneoplasias from normal controls [@armour_machine_2023].\nOptiFit opens a new door for microbial ecologists to deploy ML models using\nhigher quality OTUs than were possible before.\n\n### Microbiome models for prediction of severe CDI outcomes\n\nPrior studies to date have trained models to predict severe CDI outcomes using\nroutine clinical data, selected serum biomarkers, curated variables from EHR\ndata, or entire EHRs.\nHowever, none have focused on using the initial taxonomic composition of the gut\nmicrobiome to predict CDI severity, despite ample evidence for a link between\ndysbiosis and _C. difficile_ colonization, infection, and recurrence.\nWe trained models on OTU relative abundances collected on the day of CDI\ndiagnosis to predict four different definitions of severity.\nModels trained to predict the pragmatic severity definition performed best, as\nthis definition uses as much data as possible while also using physicians'\ndeterminations of whether severe outcomes were CDI-attributable when available.\nWhile these models did not outperform prior EHR-based models extracted two days\nafter diagnosis, the pragmatic severity models matched the performance of\nEHR-based models from the day of diagnosis.\nThese results provide an initial exploration of the utility of OTU-based models\nfor predicting CDI severity, and they may become more clinically relevant in the\nfuture as new evidence emerges of efficacious treatments for preventing severity.\n\n### Educational resources\n\nIn Chapter 4.2, we introduced a new curriculum to teach introductory Python for\ndata science via live-coding or a flipped classroom format.\nWe deployed the curriculum for in-person and virtual Girls Who Code clubs during\na three year period with high school students as the audience.\nThe curriculum takes students from having no knowledge of programming to being\nable to analyze a real-world dataset and present their findings to the group.\nIn a post-survey, students overwhelmingly reported that they improved their\nPython programming skills, problem solving and critical thinking, collaboration\nwith others, and self-confidence.\nNot only were the students we taught positively impacted; our curriculum is\nfree and available with an open source license so any other educators can use\nour curriculum or modify it for their own needs.\nThis curriculum is continually improved upon and is still in use for the chapter\nof Girls Who Code at the University of Michigan Department of Computational\nMedicine and Bioinformatics.\n\nIn Chapter 4.3, we introduced a new curriculum to teach coding for reproducible\nresearch practices to scientists and other researchers in an academic setting.\nThe Carpentries materials that inspired us taught three topics in a disparate\nmanner: introductory R programming, the Unix shell, and version control with\ngit and GitHub.\nOur curriculum covers these topics in an integrated manner so that learners\nunderstand how they are used together in practice.\nWe piloted the curriculum in a virtual workshop and assessed our work with a\npost-workshop survey.\nOn average, learners reported that they felt more confident writing programs,\nusing programming to work with data, overcoming problems while programming, and\nsearching for answers to technical questions online.\nThis curriculum is still in use today for Carpentries workshops at the\nUniversity of Michigan and is freely available with an open source license for\nanyone to use and modify.\n\n### Software\n\nIn Chapter 4.4, we introduced a tool that integrates current best practices\nfor ML in a user-friendly R package.\nOur goal was to enable researchers who are novices in ML to train and evaluate\nmodels with guard rails to prevent common pitfalls, while allowing experienced\nusers to tailor the package for advanced needs.\nAt the time of this writing, mikropml has been downloaded 13,471\ntimes from the Comprehensive R Archive Network and 24,727 times\nfrom the Anaconda package manager, suggesting a healthy user base.\nThe reach of mikropml has expanded outside of our immediate scientific network\nand into fields spanning gut microbiome research, microbial ecology, public\nhealth, and environmental research.\nRather than write code intended for one-time-use-only to conduct the ML analyses\nwe routinely perform, we chose to bundle our methods into a package for others\nwithin and outside our lab to reuse for their own research.\nAs a result, our efforts have contributed directly to the greater scientific\nendeavor, with 18 citations to date of the mikropml publication.\n\nIn addition to mikropml, other software tools were developed while conducting\nthe research described in this dissertation.\nThese include: \nschtools, an R package for processing output from the mothur program and\nmiscellaneous functions for microbiome research [@sovacool_schtools_2022];\nthe mikropml snakemake workflow, a template for building reusable and scalable\nmachine learning pipelines with mikropml for use in high performance computing\nenvironments [@sovacool_mikropml_2023],\nand the mothur snakemake workflow, a template implementing the mothur MiSeq SOP\nfor processing 16S rRNA gene amplicon sequence data and authoring reproducible \nscientific manuscripts [@sovacool_mothur_2023].\nWhile we have not published any stand-alone papers to describe these tools, they\nhave been used within the Schloss Lab for several manuscripts-in-process as well\nas published studies [@armour_machine_2023;@barron_intestinal_2022].\n\n## Future work\n\nBelow, we discuss key areas of improvement and propose ideas to build on the\nwork described in Chapters 2 through 4.\n\n### Integrate microbiota with clinical factors for improved CDI severity prediction\n\nOur OTU-based models described in Chapter 3 were trained on a different dataset\nas the EHR-based models we compared them to.\nSince the different datasets have different proportions of severe cases,\nprecision and AUPRC are not directly comparable.\nWhile AUROC has the same baseline regardless of the dataset and is thus always\ndirectly comparable, it is not as useful for rare outcomes because the model\nmay identify many true negatives but few true positives and yet report a high\nAUROC.\nA more salient comparison would train models on the same cohort of patients\nusing either OTUs, EHRs, or both in order to determine which approach leads to\nthe best performance in terms of AUPRC.\nHowever, to demonstrate clinical value, it is not enough to simply show that one\nmodeling approach outperforms another.\nHow a model might improve clinical practice if it were deployed must be\nconsidered.\nThis especially relates to the treatment options available along with their\npotential risks, which influences which performance metrics are most meaningful.\nA large increase in AUROC, AUPRC, or other metrics may or may not translate to a\nlarge increase in benefit to patients.\nIn situations where predicting a severe case may lead clinicians to choose a\ntreatment option that has an established record of safety, such as oral\nfidaxomicin instead of vancomycin, some false positives are tolerable to a\ncertain extent and a lower precision is acceptable (although still better than\na no-skill model).\nOn the other hand, if new evidence were to emerge of a treatment preventing\nsevere outcomes but with substantial risk of negative side effects, fewer false\npositives and a higher precision would be required.\nCollaborating with clinicians in the infectious dieases specialty is paramount\nto discuss the performance requried depending on the intervention at hand.\nThe ultimate goal of CDI severity prediction models is to help clinicians\nidentify early on which patients are at risk of experiencing a severe outcome\nso they can tailor treatments to prevent the outcome from ever occurring, but\ncare must be taken to ensure no harm is inflicted on patients who never would\nhave experienced a severe outcome, and to ensure that clinicians will actually\nfind the model useful to support their decision-making.\n\n#### Decision curve analysis\n\nFor the analysis of potential clinical value, we reported the precision at the\n95th percentile of risk, which is the decision threshold where 5% of cases are\npredicted to be positive and would thus undergo a different treatment in order\nto prevent the adverse outcome from occurring.\nChoosing this threshold allowed for comparison to the previously published EHR\nmodels which reported precision at that threshold.\nHowever, rather than evaluating performance at a single threshold,\nwe could extend this across a range of thresholds.\nDecision curve analysis would explore how the confusion matrix varies\nacross a range of thresholds for models of interest [@vickers_decision_2006].\nWe could then compare the net benefit, NNS, or other metrics for different\nmodeling approaches, as their relative performance may vary across decision\nthresholds.\nA model based on only OTUs may perform optimally at a different threshold than\na model based on only EHRs, and different thresholds could be selected for model\ndeployment depending on the importance of recall versus precision for the\nalternative treatment being considered by clinicians.\n\n#### Cost-benefit analysis\n\nThe costs of model training, deployment, and treatment are significant factors\nthat influence the practicality of deploying models in clinical settings.\nIf a model has good discriminative performance, it may never be used if it is\nexpensive to collect the data for deployment.\nSimilarly, an inexpensive model may never be used if the alternative treatment\nit would be paired with is too expensive.\nWe did not consider these costs when evaluating the potential clinical value,\nalthough we reported the NNS and NNB when paired with the NNT of fidaxomicin so\nthe work could be extended to consider costs as well as other treatment options.\n(For example, bezlotoxumab has also been shown to prevent recurrent CDI in\nhumans as well as systemic organ damage in mice\n[@thandavaram_efficacy_2022;@mileto_bezlotoxumab_2022].\nHowever, it is used as an adjuvant therapy and as such it does not replace\nantibiotics for CDI treatment.)\nA predictive model paired with a treatment may be cost-effective if the decrease\nin costs for averting severe outcomes outweighs the increase in treatment costs\nfor cases predicted positive plus the costs of deployment, or if any increase in\ncost is deemed worth the benefit [@kim_how_2021].\nA limitation of cost-benefit analysis techniques is that the most often used\nmetric of benefit (Quality-Adjusted Life-Years) is controversial, as it is prone\nto systematic bias and devalues health gains for patients with disabilities\n[@kim_how_2021;@loomes_use_1989;@van_osch_correcting_2004;@disability_qaly_2019].\nAlthough existing methodologies for cost-benefit analyses are imperfect,\nperforming a thorough cost-benefit analysis would provide more information about\nwhether deploying CDI severity prediction models could be worth the estimated\nbenefits gained.\n\n### Beyond taxonomic composition\n\nEfforts to find consistent changes in taxonomic composition of microbiomes\nbetween normal and dysbiotic states have found mixed success, in part because\ninterpersonal variability in taxonomic composition sometimes exceeds the\nvariability between disease states [@seekatz_role_2022;@zhu_inter-individual_2015].\nML models for diagnosing colorectal cancer or predicting severe CDI perform\nmoderately well, but may not perform well enough to justify clinical deployment.\nVariability of microbiome composition between individuals with the same disease\nstatus may be explained by functional redundancy, where different microbial\nspecies carry out the same functions and thus can replace each other with\nlittle effect on the overall function of the community [@louca_function_2018].\nExtending analyses of taxonomic composition to also include the functional\ncomposition of the microbiome may shed more light on how the microbiome changes\nin disease states. \nSequencing whole metagenomes to identify the genes present and annotate known\ngene functions is commonly used to build a profile of functional potential of\nthe microbiome.\nFunctional potential could be paired with meta-transcriptomics or\nuntargeted mass spectrometry to validate the gene products that are active in\na community, \nthus painting a more precise picture of active microbial functions than with\nmetagenomics alone.\nIncorporating the known functional potential of the microbiome from metagenomic\ndata may help account for functional redundancy and improve the performance of\nOTU-based models in classifying CRC, predicting CDI severity, or other \nmicrobiome modeling problems.\nThese insights could inform the design of future experiments to determine the\nmechanisms of dysbiosis or improve performance of ML models for clinical\ndecision making.\n\n### Continued maintenance of software tools and educational resources\n\nIt is notoriously difficult to fund the development and maintenance of\nscientific software and educational resources.\nNevertheless, we initially developed and continue to maintain the open source\ncontributions described in Chapter 4 with our discretionary time because we\nbelieve they are valuable to the scientific community and society at large.\nDeveloping software and educational resources is never a one-and-done task; they\nmust be maintained as users discover and report bugs, new methods are\ndiscovered, and the preferences of the community change over time.\nWhile no tool is designed to be used forever (despite the best intentions of\nfans of _certain_ programming languages), neglecting to maintain a tool will\nunnecessarily hasten its obsolescence.\nWe would much prefer to honor the time and effort spent during initial\ndevelopment, as well as that of end-users who adopt our tools and resources, by\ncontinuing to maintain them.\nHowever, few funding mechanisms through traditional grant-making agencies exist\nto maintain existing resources, as most value new discoveries and ideas\n[@schloss_reintroducing_2019].\nWe are hopeful that the landscape is changing for the better with the\nannouncement of programs such as the Better Software for Science initiative by\nthe Alfred P. Sloan Foundation [@sloan-better-software].\nFunding mechanisms like these will enable scientists and researchers to not only\ncreate new tools and resources but also maintain them over time, so that the\ntime, effort, and other resources expended in creating and adopting them are\nused efficiently.\n\n## Conclusions\n\nIn this work, we introduced a novel method for OTU clustering that improves the\nability of researchers to apply ML to microbiome research,\napplied ML to predict the severity of CDI infections from the composition of the \ngut microbiome,\nand introduced three new resources that empower data scientists from a broad\nrange of backgrounds to go from coding novices to ML practitioners.\nThis dissertation advances bioinformatics for microbiome research\nfrom the start of the data analysis pipeline through applying machine learning\nto biological and clinical problems, and ultimately toward enabling other\nscientists to reproduce, replicate, and build upon our work.\n",
    "supporting": [
      "discussion_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}