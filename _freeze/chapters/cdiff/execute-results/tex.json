{
  "hash": "4db8edac7ea029cc064457cffe840534",
  "result": {
    "markdown": "# Predicting Severity of _C. difficile_ Infections from the Taxonomic Composition of the Gut Microbiome\n\n\n\n\n::: {.cell}\n\n:::\n\n\n## Preamble\n\nThis chapter aims to predict CDI severity from the taxonomic composition of the gut\nmicrobiome.\nWe trained models on OTU relative abundances to predict four different severity\ndefinitions,\nidentified features of the microbiota that may prevent or promote severity,\nand assessed the potential clinical value of micriobiome-based\nprediction models.\n\nI performed all of the analysis and created the figures and tables for this chapter.\nOther co-authors helped to conceive of the study, processed samples, and\nassisted in training ML models.\nThis chapter will be submitted to a peer-reviewed journal with the following\nco-authors:\nKelly L. Sovacool, Sarah E. Tomkovich, Megan L. Coden, Jenna Wiens,\nVincent B. Young, Krishna Rao, and Patrick D. Schloss.\n\n<!--\n### another abstract?\n\nPrior studies to date have trained models to predict severe CDI outcomes using\nroutine clinical data, selected serum biomarkers, curated variables from EHR\ndata, or entire EHRs.\nThe ultimate goal is to build models that can be used to predict soon after\ndiagnosis which patients are at risk of experiencing disease-related\ncomplications so that clinicians can tailor treatments to prevent severe\noutcomes.\nWhile age and immunocompetence are important factors in CDI severity, the role\nof the gut microbiome has been under-explored.\nIn mouse studies, the gut microbiota prior to _C. difficile_ exposure\nhave been associated with differences in _C. difficile_ colonization, infection,\nclearance, and moribundity.\nAs a result, we hypothesized that the initial state of the microbiome could be\nused to predict severe CDI outcomes in humans.\nWe profiled the taxonomic composition of the bacterial microbiota from stool\nsamples collected on the day of diagnosis from 1,277 CDI patients, then\ntrained ML models to predict CDI severity using four different severity\ndefinitions.\nWe found that using as much data as possible for model training while using\nphysicians' determinations of CDI-attributable severity when available were\nparamount for good model performance, as the severity outcomes were highly\nimbalanced.\n_Enterococcus_ was the most important OTU contributing to model performance and\nwas associated with severity, which concords well with the literature.\nOur model performed as well as a prior EHR-based model extracted on the day of\ndiagnosis, but not as well as an EHR-based model extracted two days after\ndiagnosis.\nA preliminary analysis of the potential clinical value of severity prediction\nmodels showed modest performance at the 95th percentile of risk, but further\nwork is needed to determine whether deploying OTU-based models would mark an\nimprovement over current clinical practices.\n-->\n\n## Introduction\n\n_Clostridoides difficile_ infection (CDI) is the most common nosocomial\ninfection in the United States, and community-acquired cases are on the rise\n[@magill_multistate_2014;@feuerstadt_burden_2023].\nThe classic CDI case typically occurs soon after antibiotic use, which perturbs the\nprotective gut microbiota and allows _C. difficile_ to proliferate [@kelly_can_2012].\nNon-antibiotic medications including proton-pump inhibitors and osmotic laxatives\nhave also been associated with increased CDI susceptibilty and inhibited clearance\n[@janarthanan_clostridium_2012;@tomkovich_osmotic_2021].\nDiarrhea is the primary symptom, with some patients developing colitis,\ntoxic megacolon, or requiring intensive care with an in-hospital mortality rate\nof approximately 8-9% [@lucado_clostridium_2012;@kassam_clostridium_2016].\nFurthermore, 5-20% of initial cases reoccur within 2-8 weeks, and recurrent\ncases are associated with increased morbidity and mortality risk\n[@napolitano_clostridium_2017;@kelly_can_2012].\nPatient risk factors for CDI-related morbidity and mortality include age greater\nthan 65 years, history of recurrent CDI, and co-morbid chronic illnesses [@ressler_defining_2021].\nCDI remains a significant burden on the US health care system with approximately\n500,000 cases annually [@guh_trends_2020;@kwon_morbidity_2015].\n\nThere is a need for robust, accurate methods to identify patients at risk of\nsevere CDI outcomes.\nWhen paired with treatment options that may reduce risk of severity, prediction\nmodels can guide clinician decision-making to improve patient outcomes while\nminimizing harms and costs from unnecessary treatment.\nClinicians could choose more aggressive treatment options for patients predicted\nas being at high risk for severity, while using less costly or less invasive\ntreatments for low-risk patients.\nNumerous scoring systems for predicting severe CDI outcomes based on patient\nclinical factors have been developed, but none have generalized to external\ndatasets nor are any in use in routine clinical practice\n[@chakra_prediction_2012;@perry_external_2022].\nRather than relying on limited sets of human-curated variables,\nmachine learning (ML) is a promising approach that allows for use of thousands\nof features to classify samples and predict outcomes.\nIndeed, ML models trained on entire electronic health record (EHR) data\nhave demonstrated improved performance over curated models\n[@rao_clostridium_2015;@li_using_2019].\nHowever, EHR-based ML models also suffer from generalizability issues as EHR\nstandards and structures vary widely across hospital systems, making it\ndifficult to integrate disparate EHR data and deploy models in different\nhospitals [@hofer_realistically_2020].\n\nAside from patient factors encoded in EHRs,\nthe state of the patient gut microbiome is a promising factor to predict\nseverity, as the host microbiota can play either a protective or harmful\nrole in _C. difficile_ colonization, infection, and clearance.\nMouse studies have found that the initial taxonomic composition of the gut\nmicrobiome predicts differences in clearance, moribundity, and cecal tissue\ndamage in mice infected with CDI [@tomkovich_initial_2020;@lesniak_gut_2022].\nIdentifying features of the human gut microbiota that promote or prevent severe\ninfections can guide further experiments to elucidate microbial mechanisms of\nCDI severity, and incorporating these features into CDI severity models may\nimprove model performance to help guide clinical treatment decisions.\nFurthermore, ML models trained on microbiome data may be more generalizable\nacross disparate datasets compared to EHR data as long as the same metagenomic\nor marker gene sequencing protocol is used across datasets [@li_performance_2023].\nWhile the variables encoded in EHRs vary across hospitals depending on\nindividual hospital practices and the EHR software vendor used, the definition\nof a microbial marker gene is universal.\n\nWe set out to investigate whether ML models trained on the taxonomic composition\nof the gut microbiome can predict CDI severity in a human cohort,\nwhether the severity definition employed affects model performance,\nand whether there is potential clinical value in deploying OTU-based models.\nStool samples from 1,277 CDI patients were collected on the day of\ndiagnosis and 16S rRNA gene amplicon sequencing was performed, followed by\nclustering sequences into Operational Taxonomic Units (OTUs).\nWe then trained ML models to classify or predict each of four severity\ndefinitions from OTU relative abundances,\nidentified which microbial features contributed most to model performance, and\nconducted a proof-of-concept analysis of the potential clinical value of these\nOTU-based models and compared these to prior EHR-based models.\n\n## Results\n\n### CDI severity\n\nThere is not currently a consensus definition of CDI severity.\nSome scoring systems leverage clinical data available during the course of CDI,\nwhile others focus on adverse outcomes of CDI at 30 days after diagnosis\n[@ressler_defining_2021;@dieterle_systemic_2020].\nWe explored four different ways to define CDI cases as severe or not (@fig-flowchart).\nThe Infectious Diseases Society of America (IDSA) definition of severe CDI is\nbased on laboratory values collected on the day of diagnosis, with a case being\nsevere if serum creatinine level is greater than or equal to $1.5 mg/dL$ and the\nwhite blood cell count is greater than or equal to $15 k/\\mu L$\n[@mcdonald_clinical_2018].\nAlthough data for the IDSA score is straightforward to collect, it is known to\nbe a poor predictor of adverse outcomes [@stevens_validation_2020].\nThe remaining definitions we employed focus on the occurrence of adverse\noutcomes, which may be more clinically relevant.\nThe \"attributable\" severity definition is based on disease-related complications\ndefined by the Centers for Disease Control and Prevention, where an adverse\nevent of ICU admission, colectomy, or death occurs within 30 days of CDI\ndiagnosis, and the adverse event is determined to be attributable to the CDI by\nphysician chart review [@mcdonald_recommendations_2007].\nHowever, physician chart review is time-consuming and has not been completed for\nall cases (n=46 out of 86 cases with an adverse\noutcome), so we defined \"all-cause\" severity where a case is severe if an\nadverse event occurs within 30 days of the diagnosis regardless of the cause of\nthe adverse event.\nFinally, we defined a \"pragmatic\" severity definition that makes use of the\nattributable definition when available and uses the all-cause definition when\nchart review has not been completed, allowing us to use as many samples as we\nhave available while taking physicians' expert opinions into account where\npossible (@fig-flowchart B).\nWe trained ML models to classify (in the case of the IDSA definition) or predict\n(in the case of the three other definitions) severity and determined how well\nOTU-based models perform for each definition.\n\n::: {#fig-flowchart fig-cap=\"CDI severity definitions.\"}\n![](/papers/severe-cdi/paper/figures/flowchart_sankey.png){width=\"6.5in\" height=\"7in\"}\n\\justify\n\\footnotesize\n**A)** Decision flow chart to define CDI cases as severe according to the\nInfectious Diseases Society of America (IDSA) based on lab values,\nthe occurrence of an adverse outcome due to any cause (All-cause),\nand the occurrence of disease-related complications confirmed as attributable to\nCDI with chart review (Attributable).\n**B)** The proportion of severe CDI cases labelled according to each definition.\nAn additional 'Pragmatic' severity definition uses the Attributable definition\nwhen possible, and falls back to the All-cause definition when chart review is\nnot available.\nSee @tbl-counts for sample counts and proportions of severe cases across\nseverity definitions.\n:::\n\n\n::: {#tbl-counts .cell layout-ncol=\"2\" tbl-pos='h' tbl-cap='**Sample counts and proportion of severe cases.** Each severity definition has a different number of patient samples available, as well as a different proportion of cases labelled as severe. ' tbl-subcap='[\"Full datasets\",\"Intersection of samples with all labels available\"]'}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\\begingroup\\fontsize{10}{12}\\selectfont\n\n\\begin{tabular}{l|r|r}\n\\hline\nSeverity & n & \\% severe\\\\\n\\hline\nAll-cause & 1,218 & 7.1\\\\\n\\hline\nAttributable & 1,178 & 2.2\\\\\n\\hline\nIDSA & 1,072 & 34.2\\\\\n\\hline\nPragmatic & 1,218 & 5.4\\\\\n\\hline\n\\end{tabular}\n\\endgroup{}\n\\end{table}\n:::\n\n::: {.cell-output-display}\n\\begin{table}\n\\centering\\begingroup\\fontsize{10}{12}\\selectfont\n\n\\begin{tabular}{l|r|r}\n\\hline\nSeverity & n & \\% severe\\\\\n\\hline\nAll-cause & 993 & 4.6\\\\\n\\hline\nAttributable & 993 & 2.6\\\\\n\\hline\nIDSA & 993 & 32.7\\\\\n\\hline\nPragmatic & 993 & 2.6\\\\\n\\hline\n\\end{tabular}\n\\endgroup{}\n\\end{table}\n:::\n:::\n\n\n### Model performance\n\nWe first set out to train the best models possible for each severity definition.\nNot all samples have outcomes available for all four severity definitions due to\nmissing data for some patient lab values and incomplete chart review\n(@fig-flowchart B), thus each severity definition had a different number of\nsamples when using as many samples as possible (@tbl-counts A).\nWe referred to these as the full datasets.\nRandom forest models were trained on 100 splits of the datasets into training\nand test sets, and performance was evaluated on the held-out test set using the\narea under the receiver-operator characteristic curve (AUROC).\nSince the severity outcomes were highly imbalanced with different proportions of\nsevere samples between definitions, we also calculated the balanced precision\nand the area under the balanced precision-recall curve (AUBPRC) as first\nproposed by Wu _et al._ to describe the precision that would be expected\nif the outcomes were balanced [@wu_improved_2021].\n\n\n::: {.cell}\n\n:::\n\n\nAfter training on the full datasets, the performance as measured by the AUROCs\nof the training set cross-validation folds were similar to those of the held-out\ntest sets, indicating that the models are neither overfit nor underfit\n(@fig-performance A).\nAs measured by AUROC on the held-out test sets, models predicting pragmatic\nseverity performed best with a median AUROC of 0.69,\nand this was significantly different from that of the other definitions\non the full datasets (P < 0.05).\nModels predicting IDSA, all-cause, and attributable severity performed similarly\nwith median test set AUROCs of\n0.61,\n0.63, and\n0.61 respectively.\nThe test set AUROCs were not significantly different (P > 0.05) for attributable\nand IDSA nor for attributable and all-cause, but the IDSA and all-cause AUROCs\nwere significantly different from each other (P < 0.05).\nWe plotted the receiver-operator characteristic curve and found that the\npragmatic severity models outperformed the others at all specificity values\n(@fig-performance B).\nFor comparison, a prior study with a different dataset trained a logistic\nregression model on electronic health record data extracted on the day of\nCDI diagnosis to predict attributable severity, yielding an AUROC of\n0.69 [@li_using_2019].\nWhile our attributable severity model did not meet this performance, the\npragmatic severity model performed just as well as the EHR-based model in terms\nof AUROC.\n\n::: {#fig-performance fig-cap=\"Performance of ML models.\"}\n![](/papers/severe-cdi/paper/figures/ml-performance.png){width=\"6.5in\" height=\"5.7in\"}\n\\justify\n\\footnotesize\nIn the left facets, models were trained on the full datasets, with different\nnumbers of samples available for each severity definition.\nIn the right facets, models were trained on the same dataset consisting of the\nintersection of samples with labels available for all definitions.\nNote that the intersection dataset has exactly the same labels for attributable\nand pragmatic severity, thus these have identical performance.\n**A)**\nArea under the receiver-operator characteristic curve (AUROC) for the test sets\nand cross-validation folds of the training sets, and the area under the balanced\nprecision-recall curve (AUBPRC) for the test sets.\nEach point is annotated with the median performance across 100 train/test splits\nwith tails as the 95% CI.\n**B)** Receiver-operator characteristic curves for the test sets.\nMean specificity is reported at each sensitivity value,\nwith ribbons as the 95% CI.\n**C)** Balanced precision-recall curves for the test sets.\nMean balanced precision is reported at each recall (sensitivity) value,\nwith ribbons as the 95% CI.\nOriginal unbalanced precision-recall curves are shown in Supplementary @fig-prc.\n:::\n\nSince the data are highly imbalanced with only a small proportion of CDI cases\nhaving a severe outcome, evaluating the trade-off between precision and recall\nis more informative than the receiver-operator characteristic because precision\nand recall do not consider true negatives, which may overinflate the AUROC.\nHowever, unlike for AUROC, the baseline for the area under the precision-recall\ncurve depends on the proportion of positive outcomes (i.e. severe cases) in the\ndata, which vary across these severity definitions.\nTo allow comparison of precision across datasets with different proportions of\npositives, Wu _et al._ introduced the concept of balanced precision, a\ntransformation of precision based on Bayes' theorem that represents the\nprecision that would have been expected if the proportion of positives were\nbalanced at 0.5 [@wu_improved_2021].\nReporting the area under the balanced precision-recall curve (AUBPRC) allows us\nto compare the trade-off between precision and recall for our different severity\ndefintions.\nThe test set median AUBPRCs from the full datasets followed a similar pattern as\nthe test set AUROCs with\n0.60 for IDSA severity,\n0.67 for all-cause severity,\n0.66 for attributable severity, and\n0.75 for pragmatic severity.\nThe AUBPRCs were significantly different from each other (P < 0.05) for\neach pair of severity definitions except for attributable versus all-cause.\nWe plotted the balanced precision-recall curve and found that the IDSA definition\noutperformed all other models at very low recall values, but the others outperform\nIDSA at all other points of the curve (@fig-performance C).\nThe 95% confidence intervals overlapped the baseline AUROC and AUBPRC for\nthe attributable severity models, while all others did not overlap the baseline.\n\nWhile it is advantageous to use as much data as available to train the best\nmodels possible, comparing performances of models trained on different subsets\nof the data is not entirely fair.\nTo enable fair comparisons of the model performances across different severity\ndefinitions, we also selected the intersection of samples (n=993)\nthat had labels for all four severity definitions and repeated the model\ntraining and evaluation process on this intersection dataset.\nThe attributable definition is exactly the same as the pragmatic definition for\nthe intersection dataset, as we defined pragmatic severity to use the\nattributable definition when available.\nThe performance results on the intersection dataset are shown in the right\nfacets of each panel of @fig-performance.\n\n\n::: {.cell}\n\n:::\n\n\nAs with the full datasets, the AUROCs of the training sets and test sets were\nsimilar within each severity definition.\nThe median test set AUROCs were\n0.60 for IDSA severity,\n0.55 for all-cause severity,\n0.59 and for attributable severity.\nThe AUROCs on the intersection dataset were significantly different for\nall-cause versus attributable and all-cause versus IDSA severity (P < 0.05), but not for\nIDSA versus attributable severity (P > 0.05).\nThe median test set AUBPRCs were\n0.59 for IDSA severity,\n0.55 for all-cause severity,\n0.58 and for attributable severity.\nJust as with the AUROCs, the AUBPRCs were significantly different for\nall-cause versus attributable and all-cause versus IDSA severity (P < 0.05), but not for\nIDSA versus attributable severity (P > 0.05).\nFor all severity definitions, performance dropped between the full dataset and\nthe intersection dataset since fewer samples are available, but this effect is\nleast dramatic for IDSA severity as the full and intersection datasets are more\nsimilar for this definition (@tbl-counts B).\nThe 95% confidence interval overlaps with the baseline for both AUROC and AUBPRC\nfor all definitions on the intersection dataset except for IDSA severity.\n\n### Feature importance\n\nWe performed permutation feature importance to determine which OTUs contributed\nthe most to model performance.\nAn OTU was considered important if performance decreased when it was permuted in\nat least 75% of the train/test splits, with greater differences in AUROC meaning\ngreater importance.\nWe plotted mean decrease in AUROC alongside log~10~-transformed mean\nrelative abundances for the top OTUs (@fig-features).\n_Enterococcus_ was the most important OTU, being significantly important for\nall models except for attributable severity on the full dataset.\n_Staphylococcus_ was important for the pragmatic and all-cause definitions on\nthe full datasets, but not for models trained on the intersection dataset.\n_Lactobacillus_ was important only for the all-cause definition on the intersection\ndataset.\nAll remaining OTUs had differences in AUROC < 0.02 and were only significantly\nimportant in one or two of the models at most.\nAll of the significantly importance OTUs had an increased mean relative\nabundance in severe cases relative to not severe cases.\n\n::: {#fig-features fig-cap=\"Most important OTUs for model performance.\"}\n![](/papers/severe-cdi/paper/figures/feature-importance.png){width=\"6.5in\" height=\"4.3in\"}\n\\justify\n\\footnotesize\n**A)** Feature importance via permutation test.\nFor each OTU, the order of samples was randomized in the test set 100 times and\nthe AUROC was re-calculated to estimate the permutation performance.\nOTUs with a greater difference in AUROC (actual performance minus permutation\nperformance) are more important.\nMean difference in AUROC and the 75% confidence interval (CI) is reported for\neach OTU that had a mean difference $\\geq$ 0.01 for at least one severity\ndefinition, with starred OTUs being significant for the 75% CI.\nNotably, the OTU most likely corresponding to _C. difficile_ was not important\n(see Supplementary @fig-cdiff).\nLeft: models were trained on the full datasets, with different numbers of\nsamples available for each severity definition.\nRight: models were trained on the intersection of samples with all labels\navailable for each definition. Note that Attributable and Pragmatic severity are\nexactly the same for the intersection dataset.\n*Pseudomonas* (OTU 120) is not shown for IDSA severity in the full datasets nor\nin the intersection dataset because it was removed during pre-processing due to\nhaving near-zero variance.\n**B)** Log~10~-transformed mean relative abundances of the most important OTUs\non the full datasets, grouped by severity (shape).\nThe vertical dashed line is the limit of detection.\n:::\n\n### Estimating clinical value\n\nEven if a model performs well, it may not be useful in a clinical setting unless\nit can guide clinicians to choose between treatment options.\nAt this time, we are not aware of any direct evidence that a particular\ntreatment reduces the risk of severe CDI outcomes.\nHowever, with some assumptions we offer a proof-of-concept analysis of the\npotential clinical value of OTU-based severity prediction models when paired\nwith treatments that may reduce severity.\nWhen considering the suitability of a model for deployment in clinical settings,\nthe number needed to screen (NNS) is a highly relevant metric representing how\nmany patients must be predicted as severe by the model to identify one true\npositive. NNS is calculated as the reciprocal of precision (@eq-nns) [@rembold_number_1998].\nSimilarly, the number needed to treat (NNT) is the number of true positive\npatients that must be treated by an intervention in order for one patient to\nbenefit from the treatment. NNT is calculated as the reciprocal of the absolute\nrisk reduction (ARR) from randomized controlled trials (@eq-arr and @eq-nnt)\n[@cook_number_1995;@laupacis_assessment_1988;@irwig_relative_2008].\nMultiplying NNS by NNT yields the number needed to benefit (NNB): the number\nof patients predicted to have a severe outcome who then benefit from the\ntreatment (@eq-nnb) [@liu_number_2019].\nThus the NNB pairs model performance with treatment effectiveness to estimate\nthe benefit of using predictive models in clinical practice.\nLower values of NNS, NNT, and NNB are better, with the minimum value being 1,\nas fewer patients must be screened and treated in order to benefit a single patient.\n\n$$\nNNS = \\frac{1}{Precision}\n$$ {#eq-nns}\n$$\nARR = Control\\ Event\\ Rate - Experimental\\ Event\\ Rate\n$$ {#eq-arr}\n$$\nNNT = \\frac{1}{ARR}\n$$ {#eq-nnt}\n$$\nNNB = NNS \\times NNT\n$$ {#eq-nnb}\n\nCurrent clinical guidelines specify vancomycin and fidaxomicin as the standard\nantibiotics to treat CDI, with a preference for fidaxomicin due to its higher\nrate of sustained resolution of CDI and lower rate of recurrence\n[@johnson_clinical_2021].\nThe NNTs of fidaxomicin for sustained resolution and prevention of recurrence\nare each estimated to be 10 [@long_oral_2022;@tashiro_oral_2022].\nHowever, fidaxomicin is considerably more expensive than vancomycin.\nIf fidaxomicin were shown to reduce the risk of severe CDI outcomes, it could be\npreferentially prescribed to patients predicted to be at risk, while prescribing\nvancomycin to low-risk patients.\nIf we assume that the superior efficacy of fidaxomicin for sustained resolution\nand reduced recurrence also translates to reducing the risk of severe outcomes,\nwe can pair the NNT of fidaxomicin with the NNS of OTU-based prediction models\nto estimate the NNB.\n\n::: {#fig-risk fig-cap=\"Model performance in terms of the number needed to screen across decision thresholds and risk percentiles.\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](cdiff_files/figure-pdf/plot_risk_thresholds-1.pdf)\n:::\n:::\n\n\\justify\n\\footnotesize\nThe number needed to screen (NNS) represents how many patients must be predicted\nas severe by the model to identify one true positive (@eq-nns).\nNNS ranges from 1 to infinity, with 1 being perfect.\n**A)**\nThe median NNS was computed for each decision threshold from\n0 to 1, incremented by 0.05.\nA decision threshold of 0.20 means that patients with at least a 20% risk of\nseverity are predicted as severe.\nThe points mark the decision threshold at the 95th percentile of risk for each\nseverity prediction model, which corresponds to 5% of cases predicted to have a\nsevere outcome.\n**B)**\nThe median NNS is shown across risk percentiles. The vertical dashed line marks\nthe 95th percentile of risk.\n:::\n\nTo calculate a clinically-relevant NNS for these models, we computed the\nNNS across decision thresholds and risk percentiles for each\nprediction model trained on the full datasets (@fig-risk).\nWe excluded the IDSA severity models as the IDSA severity scores were calculated\non the day of diagnosis, thus they are classification rather than prediction\nproblems.\nFurthermore, IDSA severity scores do not correlate well with disease-related\nadverse events which are a more salient outcome to prevent.\nWe report the median NNS for each decision threshold and risk percentile from\n0 to 1 (@fig-risk).\nThe decision threshold is the risk level at which patients are predicted to have a\nsevere outcome.\nFor example, a decision threshold of 0.20 means that patients with at least a\n20% risk of severity are predicted to have a severe outcome by the model.\nThe decision threshold at a given risk percentile is different for each model,\nwith the 95th percentile of risk corresponding to the decision threshold where\n5% of patients are predicted to have a severe outcome.\n\nWe further focused on the 95th percentile of risk in order to compare our models\nto EHR-based models from prior studies that reported model precision at this\nrisk threshold.\nAmong the models predicting severe outcomes, those trained on the full\ndatasets performed best with an NNS of 5 for the all-cause\ndefinition, 12 for the attributable definition, and\n5.5 for the pragmatic definition at the 95th percentile of risk (@fig-risk).\nMultiplying the NNS of the OTU-based models by the estimated NNT of\n10 for fidaxomicin yields NNB values of 50\nfor all-cause severity, 120 for attributable severity,\nand 55 for pragmatic severity.\nThus, in a hypothetical scenario where these assumptions about fidaxomicin hold\ntrue, at best 50 and at worst 120 patients would need to be\npredicted to experience a severe outcome and be treated with fidaxomicin in\norder for one patient to benefit, with the all-cause severity models yielding\nthe best performance.\nFor comparison, prior studies predicted CDI-attributable severity using\nelectronic health record data extracted two days after diagnosis and from a\nsmaller set of manually curated variables, achieving precision values of 0.42 \n(NNS = 2.4) for the EHR model and 0.17 (NNS = 6.0)\nfor the curated model at the 95th percentile of risk [@li_using_2019;@rao_clostridium_2015].\nPairing the prior EHR-based model with fidaxomicin would yield an NNB of 24.\nThus the all-cause and pragmatic OTU-based models outperformed the curated model\nbut not the EHR-based model, although the EHR data were extracted two days after\ndiagnosis while OTUs in this study are from stool samples collected on the day\nof diagnosis.\nThese estimates represent a proof-of-concept demonstration of the potential\nvalue and trade-offs of deploying severity prediction models trained on\nmicrobial factors versus EHRs to guide clinicians' treatment decisions.\n<!--\nTODO possible to find NNS on day of diagnosis for EHR model?\n-->\n\n## Discussion\n\nWe trained ML models based on gut microbial communities on the day of CDI\ndiagnosis to predict CDI severity according to four different severity definitions.\nThe purpose of the full datasets was to train the best models possible given the\nconstraints, while using the intersection dataset allows for comparing severity\ndefinitions.\nWe found that models predicting pragmatic severity with as much data as\navailable performed best, while models classifying IDSA severity outperformed\nthe all-cause and attributable definitions only with the intersection.\nPerformance dropped substantially when reducing to the intersection dataset for\nall definitions, likely due to the particularly imbalanced nature of the\nall-cause and attributable definitions.\nThese results demonstrate the importance of using as many samples as possible when\ndata are sparse and the outcome is low prevalence, as well as the need to\nincorporate physician's expertise when possible.\n\nPermutation feature importance revealed patterns of important bacteria that\nconcord with the literature.\nEnrichment of _Enterococcus_ and _Lactobacillus_ in _C. difficile_ infection and\nseverity have been well-documented in prior studies, thus their importance and\nincrease in abundance for severe cases is not surprising\n[@schubert_microbiome_2014;\n@antharam_intestinal_2013;\n@berkell_microbiota-based_2021;\n@lesniak_gut_2022].\nFor many of the top OTUs, there is a wide range in importance.\nNotably, the OTU represented by _Pseudomonas_ had wide variance in importance\nfor the full dataset in models predicting attributable severity, with the\nmaximum point more important than any other OTU yet a minimum below zero.\nHowever, for the intersection dataset, this OTU was removed due to having\nnear-zero variance.\nThe presence of _Pseudomonas_ was thus informative in a small number of\npatient samples, but not in others, and these samples were lost in the\nintersection dataset.\nOverall the abundance data are patchy, as these patients were likely all taking\nantibiotics for unrelated infections prior to CDI onset.\nA limitation of permutation importance is that the contribution of each feature\nis considered in isolation, but members of microbial communities interact and\ncompete with each other, thus these complicated relationships are not well\ncaptured by permutation importance.\n\nThe full pragmatic severity model performed just as well as a prior\nEHR-based model trained on the day of diagnosis, demonstrating the potential\nutility of OTU-based models.\nIn terms of the number needed to screen, the OTU-based pragmatic and all-cause\nseverity models outperformed a prior model of manually curated clinical\nvariables, but not a model trained on EHR data extracted two days after\ndiagnosis.\nThe attributable definition had the worst NNS of all models, despite its\nclinical relevance.\nObtaining EHR data for the dataset in this study would allow a more direct\ncomparison of the performance of models trained on OTUs, EHRs, or both, as well\nas extracting EHR data on the day of diagnosis rather than two days after.\n\nHowever, it is not enough for models to perform well to justify deploying them\nin a clinical setting; benefit over current practices must be shown [@wiens_no_2019].\nAlthough no known treatment options have been shown to reduce the risk of severe\nCDI outcomes, fidaxomicin is promising due to its improved time to resolution\nand reduced recurrence.\nDespite its increased cost, fidaxomicin is also attractive as a preferential\nantibiotic option as vancomycin-resistant _Enterococcus_ is on the rise and\nenterococci are known to worsen CDI\n[@poduval_clostridium_2000;@smith_enterococci_2022].\nWe extended our analysis of clinical value to incorporate the number needed to\ntreat for fidaxomicin alongside the predictive models in order to calculate the\nnumber needed to benefit.\nThe NNB contextualizes model performance within clinical reality, as it combines\nboth model performance and treatment effectiveness [@liu_number_2019].\nA more robust analysis of clinical value would further consider the cost of\ntreatment options versus the savings of averting severe outcomes across a range\nof decision thresholds, as economic disparities are a major barrier to treatment\nin the US [@johnson_clinical_2021].\nCost-benefit analyses based on clinical trial data have reported that\nfidaxomicin may be as cost-effective as vancomycin as a treatment for initial\nCDI cases, largely due to the reduced risk of recurrence\n[@jiang_budget_2022;@reveles_fidaxomicin_2017].\nWhile our analysis of clinical value is only a proof-of-concept, if evidence\nemerges that new or existing treatments significantly reduce the risk of severe\nCDI, our results can be incorporated into future considerations of whether to\nbuild severity prediction models and what features should be incorporated.\nIn practice, EHR-based models are less costly to deploy than OTU-based models\nand do not require additional clinical sample collection.\nHowever, EHR systems notoriously lack interoperability across hospitals, which\ninhibits the ability of EHR-based models to generalize to datasets from\ndifferent hospitals.\nOTU-based models may be more generalizable across disparate hospital systems\nthan EHR-based models as long as the same sample collection and sequencing\nprotocol is used.\nAmplicon sequencing is not typically performed for CDI patients, however,\nroutinely profiling the microbial communities of CDI patients could be justified\nif models that incorporate microbial features were shown to improve patient\noutcomes.\n\nIn all, we found that our models to predict severity from features of the gut\nmicrobiome performed moderately well.\nOur approach enabled us to identify bacteria that contributed to model\nperformance and evaluate how well the state of the gut microbiome can predict\nseveral different definitions of CDI severity.\nFurther work is needed to determine whether the performance of OTU-based models\nis sufficient to justify their deployment in clinical settings, especially as\ncompared to EHR-based models.\nIf and when new evidence emerges of improved treatments to prevent severe CDI\noutcomes, deploying performant and robust models for clinicians to tailor\ntreatment options may improve patient outcomes and reduce the burden of severe\nCDI.\n\n## Materials and Methods\n\n### Sample collection\n\nThis study was approved by the University of Michigan Institutional Review\nBoard. Samples were collected from patients diagnosed with CDI by the University\nof Michigan Health System from January 2016 through December 2017.\nStool samples that had unformed stool consistency were tested for *C. difficile*\nby the clinical microbiology lab with a two-step algorithm that included\ndetection of *C. difficile* glutamate dehydrogenase and toxins A and B by enzyme\nimmunoassay with reflex to PCR for the *tcdB* gene when results were discordant.\n1,517 stool samples were collected from patients diagnosed with a CDI.\nLeftover stool samples that were sent to the clinical microbiology lab were\ncollected and split into different aliquots.\nFor 16S sequencing, the aliquot of stool was re-suspended in\nDNA genotek stabilization buffer and then stored in the -80&deg;C freezer.\n\n### 16S rRNA gene amplicon sequencing\n\nSamples stored in DNA genotek buffer were thawed from the -80&deg;C, vortexed,\nand then transferred to a 96-well bead beating plate for DNA extractions.\nDNA was extracted using the DNeasy\nPowersoil HTP 96 kit (Qiagen) and an EpMotion 5075 automated pipetting system\n(Eppendorf).\nThe V4 region of the 16S rRNA gene was amplified with the AccuPrime\nPfx DNA polymerase (Thermo Fisher Scientific) using custom barcoded primers, as\npreviously described [@kozich_development_2013].\nEach library preparation plate for\nsequencing contained a negative control (water) and mock community control\n(ZymoBIOMICS microbial community DNA standards).\nThe PCR amplicons were\nnormalized (SequalPrep normalization plate kit from Thermo Fisher Scientific),\npooled and quantified (KAPA library quantification kit from KAPA Biosystems),\nand sequenced with the MiSeq system (Illumina).\n\nAll sequences were processed with mothur (v1.46) using the MiSeq SOP protocol\n[@schloss_introducing_2009; @kozich_development_2013].\nPaired sequencing reads were combined and aligned with the SILVA (v132)\nreference database [@quast_silva_2013] and taxonomy was assigned with a modified\nversion of the Ribosomal Database Project reference sequences (v16)\n[@cole_ribosomal_2014].\nSequences were clustered into _de novo_ OTUs with the OptiClust algorithm in\nmothur [@westcott_opticlust_2017], resulting in 9,939 OTUs.\nSamples were then subsampled to 5,000 sequences per sample.\nOnly the first CDI sample per patient was used for subsequent ML analyses such\nthat no patient is represented more than once, resulting in a dataset of\n1,277 samples.\n\n### Defining CDI severity\n\nWe chose to explore four different ways to define CDI cases as severe or not (@fig-flowchart).\n\n- **IDSA**: A case is severe if serum creatinine level is greater than or equal\n  to $1.5 mg/dL$ and the white blood cell count is greater than or equal to\n  $15 k/\\mu L$ on the day of diagnosis [@mcdonald_clinical_2018].\n- **All-cause**: A case is severe if ICU admission, colectomy, or death\n  occurred within 30 days of CDI diagnosis, regardless of the cause of the\n  adverse event.\n- **Attributable**: A case is severe if an adverse event of ICU admission,\n  colectomy, or death occurred within 30 days of CDI diagnosis, and the adverse\n  event was determined to be attributable to the CDI by two physicians who\n  reviewed the medical chart [@mcdonald_recommendations_2007].\n- **Pragmatic**: A case's severity is determined by the attributable definition\n  if it is available, otherwise it is determiend by the all-cause definition.\n\n### Model training\n\nRandom forest models were used to examine whether OTU data collected on the day\nof diagnosis could classify CDI cases as severe according to each severity\ndefinition.\nWe used the mikropml R package v1.5.0 [@topcuoglu_mikropml_2021] implemented in\na custom version of the mikropml Snakemake workflow [@sovacool_mikropml_2023]\nfor all steps of the machine learning analysis.\nWe have full datasets which use all samples available for each severity\ndefinition, and an intersection dataset which consists of only the samples that\nhave all four definitions labelled.\nThe intersection dataset is the most fair for comparing model performance across\ndefinitions, while the full dataset allows us to use as much data as possible\nfor model training and evaluation.\nDatasets were pre-processed with the default options in mikropml to remove\nfeatures with near-zero variance and scale continuous features from -1 to 1.\nDuring pre-processing,\n9,757 to 9,760\nfeatures were removed due to having near-zero variance, resulting in datasets\nhaving 179 to 182 features\ndepending on the severity definition.\nNo features had missing values and no features were perfectly correlated.\nWe randomly split the data into an 80% training and 20% test set and repeated\nthis 100 times, followed by training models with 5-fold cross-validation.\n\n### Model evaluation\n\nModel performance was calculated on the held-out test sets using the area under\nthe receiver-operator characteristic curve (AUROC) and the area under the\nbalanced precision-recall curve (AUBPRC).\nStatistical significance for differences in performance across severity\ndefinitions was determined via permutation tests at an alpha level of 0.05.\nPermutation feature importance was then performed to determine which OTUs\ncontributed most to model performance.\nWe reported OTUs with a significant permutation test at an alpha level of 0.05\nin at least 75 of the 100 train/test splits for any severity definition.\n\nSince the severity labels are imbalanced with different frequencies of severity\nfor each definition, we calculated balanced precision, the precision expected if\nthe labels were balanced.\nThe balanced precision and the area under the balanced precision-recall curve\n(AUBPRC) were calculated with Equations 1 and 7 from Wu _et al._ [@wu_improved_2021].\n\n### Number needed to benefit\n\nFor the severity prediction models (which excludes the IDSA definition),\nwe set out to estimate the potential benefit of deploying models in clinical\nsettings.\nWe determined the decision threshold at the 95th percentile of risk for each\nmodel, which corresponds to 5% of cases being predicted by the model to\nexperience a severe outcome.\nAt this threshold we computed the number needed to screen (NNS), which is the\nreciprocal of precision and represents the number of cases that must be\npredicted as severe to identify one true positive (@eq-nns) [@rembold_number_1998].\nThe number needed to treat (NNT) is the number of true positive patients that\nmust be treated by an intervention in order for one patient to benefit, and is\ncalculated from the reciprocal of absolute risk reduction in randomized\ncontrolled trials (@eq-nnt and @eq-arr) [@cook_number_1995;@laupacis_assessment_1988;@irwig_relative_2008].\nMultiplying the NNS of a model by the NNT of a treatment yields the number\nneeded to benefit (NNB) - the number of patients that must be predicted to have\na severe outcome and undergo a treatment to benefit from it \n(@eq-nnb) [@liu_number_2019].\nNNB encapsulates the benefit of pairing a predictive model with a treatment in\na clinical setting, with lower NNB numbers being better.\n\n### Code availability\n\nThe complete workflow, code, and supporting files required to reproduce this\nmanuscript with accompanying figures is available on\nGitHub (<https://github.com/SchlossLab/severe-CDI>)\nand archived in Zenodo [@severe-CDI-zenodo].\n\nThe workflow was defined with Snakemake [@koster_snakemake_2012] and\ndependencies were managed with conda environments.\nScripts were written in R [@r_core_team_r_2023],\nPython [@van_rossum_python_2009],\nand GNU bash.\nAdditional software and packages used in the creation of this manuscript include\ncowplot [@wilke_cowplot_2020],\nggtext [@wilke_ggtext_2020],\nggsankey [@sjoberg_ggsankey_2022],\nschtools [@sovacool_schtools_2022],\nthe tidyverse metapackage [@wickham_welcome_2019],\nQuarto, and\nvegan [@oksanen_vegan_2023].\n\n### Data availability\n\nThe 16S rRNA sequencing data have been deposited in the National Center for\nBiotechnology Information Sequence Read Archive\n(BioProject Accession no. PRJNA729511).\n\n## Acknowledgements\n\nWe thank the patients for donating stool samples and the research team members\nwho collected, stored, and processed the samples.\n\n<!--\n### Author contributions\n\nKLS performed data processing, trained machine learning models, wrote the\nanalysis code, created the figures and tables, and wrote the original draft of\nthe manuscript.\nSET processed samples, performed initial analysis of IDSA severity scores, and\ncontributed analysis code.\nMLC contributed analysis code and assisted in training machine learning models.\nJW, VBY, and KR directed the analysis of clinical value.\nPDS conceived of the study and supervised the project.\nAll authors reviewed and edited the manuscript.\n\n### Funding\n\nTODO\n\n-->\n\n\n## Supplement\n\n::: {#fig-prc fig-cap=\"Precision-recall curves.\" fig-pos='H'}\n![](/papers/severe-cdi/paper/figures/prc_curves.png){width=\"6.5in\" height=\"3.5in\"}\n\\justify\n\\footnotesize\nThe original precision-recall curves for each model.\nThe horizontal line is the baseline precision, i.e. the proportion of severe\ncases in the dataset for each severity definition.\nSince each definition has a different baseline precision, the PRCs cannot be\ncompared directly without balancing the precision (see @fig-performance).\n:::\n\n::: {#fig-cdiff fig-cap=\"_C. difficile_ relative abundance and feature importance.\" fig-pos='H'}\n![](/papers/severe-cdi/paper/figures/cdiff-otu.png){width=\"6.5in\" height=\"4.7in\"}\n\\justify\n\\footnotesize\nOf the 45 OTUs belonging to the _Peptostreptococcaceae_ family, only one\n(OTU 25) had abundance values above the limit of detection.\n**Left**: log~10~-transformed relative abundance of OTU 25 in the full datasets.\nThe dashed line is the limit of detection.\n**Right**: Permutation feature importance as measured by AUROC for OTU 25.\nThe point is the mean difference in AUROC and the tails are the 75% confidence\ninterval.\nThe dotted line is a feature importance of zero, meaning the feature is not\nimportant.\n:::\n\n<!--\nTODO move aubprc to supplement? wait for committee feedback?\n-->\n\n<!-- TODO supplementary figure with alpha and beta diversity & significance.\nSamples were rarefied to 5,000 sequences per sample, repeated 1,000\ntimes for alpha and beta diversity analysis.\n-->\n\n<!-- TODO how get supplement figures labelled with S prefix\n-->\n",
    "supporting": [
      "cdiff_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{\"knit_meta_id\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]}},\"value\":[{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"array\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"multirow\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"wrapfig\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"float\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"colortbl\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"pdflscape\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"tabu\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttablex\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"ulem\"]},{\"type\":\"character\",\"attributes\":{},\"value\":[\"normalem\"]},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"makecell\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"xcolor\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]}]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}