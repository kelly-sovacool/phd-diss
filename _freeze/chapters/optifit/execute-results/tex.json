{
  "hash": "21cf06284c96812b69c4533ce4f04d2e",
  "result": {
    "markdown": "# OptiFit: an Improved Method for Fitting Amplicon Sequences to Existing OTUs\n\n\n\n\n\n## Preamble\n\nThis chapter introduces a novel algorithm, OptiFit, for performing\nreference-based clustering of amplicon sequences into Operational Taxonomic\nUnits.\nWe showed that OptiFit produces OTUs at a similar quality as other clustering\nmethods while enabling new sequences to be clustered to existing _de novo_ OTUs,\nwhich was not previously possible.\nOptiFit can be used with OTU-based machine learning models to make predictions\non new data, which we later demonstrated in a follow-up analysis [@armour_machine_2023].\n\nI performed all of the analysis and created the figures for this chapter.\nOther co-authors conceived of and implemented the OptiFit algorithm and\ncontributed analysis code.\nThis paper was originally published in 2022 in mSphere with the following co-authors:\nKelly L. Sovacool, Sarah L. Westcott, M. Brodie Mumphrey, Gabrielle A. Doston,\nand Patrick D. Schloss [@sovacool_optifit_2022].\n\n### Importance\n\nAdvancements in DNA sequencing technology have allowed researchers to\naffordably generate millions of sequence reads from microorganisms in\ndiverse environments. Efficient and robust software tools are needed to\nassign microbial sequences into taxonomic groups for characterization\nand comparison of communities. The OptiClust algorithm produces high\nquality groups by comparing sequences to each other, but the assignments\ncan change when new sequences are added to a dataset, making it\ndifficult to compare different studies. Other approaches assign\nsequences to groups by comparing them to sequences in a reference\ndatabase to produce consistent assignments, but the quality of the\ngroups produced is reduced compared to OptiClust. We developed OptiFit,\na new reference-based algorithm that produces consistent yet high\nquality assignments like OptiClust. OptiFit allows researchers to\ncompare microbial communities across different studies or add new data\nto existing studies without sacrificing the quality of the group\nassignments.\n\n## Introduction\n\nAmplicon sequencing is a mainstay of microbial ecology. Researchers can\naffordably generate millions of sequences to characterize the\ncomposition of hundreds of samples from microbial communities without\nthe need for culturing. In many analysis pipelines, 16S rRNA gene\nsequences are assigned to operational taxonomic units (OTUs) to\nfacilitate comparison of taxonomic composition between communities to\navoid the need for taxonomic classification. A distance threshold of 3%\n(or sequence similarity of 97%) is commonly used to cluster sequences\ninto OTUs based on pairwise comparisons of the sequences within the\ndataset. The method chosen for clustering affects the quality of OTU\nassignments and thus may impact downstream analyses of community\ncomposition\n[@westcott_opticlust_2017;@westcott_novo_2015]. OTU\nquality can be conceptualized as how well the OTU assignments match the\ndefinition set by the distance threshold, i.e. whether sequence pairs\nthat are at least as similar as the distance threshold are assigned to\nthe same OTU and sequence pairs that are more dissimilar than the\ndistance threshold are assigned to different OTUs.\n\nThere are two main categories of OTU clustering algorithms: *de novo*\nand reference-based. OptiClust is a *de novo* clustering algorithm which\nuses the distance score between all pairs of sequences in the dataset to\ncluster them into OTUs by maximizing the Matthews Correlation\nCoefficient (MCC) [@westcott_opticlust_2017]. This approach\ntakes into account the distances between all pairs of sequences when\nassigning query sequences to OTUs, in contrast to other *de novo*\nmethods such as the greedy clustering algorithms implemented in USEARCH\nand VSEARCH [@edgar_search_2010;\n@rognes_vsearch_2016]. In methods employing greedy clustering\nalgorithms, only the distance between each sequence and a representative\ncentroid sequence in the OTU is considered while clustering. As a\nresult, distances between pairs of sequences in the same OTU are\nfrequently larger than the specified threshold, i.e. they are false\npositives. In contrast, the OptiClust algorithm takes into account the\ndistance between all pairs of sequences when considering how to cluster\nsequences into OTUs and is thus less willing to take on false positives.\n\nA limitation of *de novo* clustering is that different OTU assignments\nwill be produced when new sequences are added to a dataset, making it\ndifficult to use *de novo* clustering to compare OTUs between different\nstudies. Furthermore, since *de novo* clustering requires calculating\nand comparing distances between all sequences in a dataset, the\nexecution time can be slow and memory requirements can be prohibitive\nfor very large datasets. Reference clustering attempts to overcome the\nlimitations of *de novo* clustering methods by using a representative\nset of sequences from a database, with each reference sequence seeding\nan OTU. Commonly, the Greengenes set of representative full length\nsequences clustered at 97% similarity is used as the reference with\nVSEARCH [@rognes_vsearch_2016;@noauthor_clustering_nodate].\nQuery sequences are then clustered into OTUs based on their similarity\nto the reference sequences. Any query sequences that are not within the\ndistance threshold to any of the reference sequences are either thrown\nout (closed reference clustering) or clustered *de novo* to create\nadditional OTUs (open reference clustering). While reference-based\nclustering is generally fast, it is limited by the diversity of the\nreference database. Novel sequences in the sample will be lost in closed\nreference mode if they are not represented by a similar sequence in the\ndatabase. We previously found that the OptiClust *de novo* clustering\nalgorithm created the highest quality OTU assignments of all clustering\nmethods [@westcott_opticlust_2017].\n\nTo overcome the limitations of current reference-based and *de novo*\nclustering algorithms while maintaining OTU quality, we developed\nOptiFit, a reference-based clustering algorithm. While other tools\nrepresent reference OTUs with a single sequence, OptiFit uses all\nsequences in existing OTUs as the reference and fits new sequences to\nthose reference OTUs. In contrast to other tools, OptiFit considers all\npairwise distance scores between reference and query sequences when\nassigning sequences to OTUs in order to produce OTUs of the highest\npossible quality. Here, we tested the OptiFit algorithm with the\nreference as a public database (e.g. Greengenes) or *de novo* OTUs\ngenerated using a reference set from the full dataset and compared the\nperformance to existing tools. To evaluate the OptiFit algorithm and\ncompare to existing methods, we used four published datasets isolated\nfrom soil [@johnston_metagenomics_2016], marine [@henson_artificial_2016],\nmouse gut [@schloss_stabilization_2012],\nand human gut [@baxter_microbiota-based_2016] samples.\nOptiFit is available within the mothur software program.\n\n## Results\n\n### The OptiFit algorithm\n\nOptiFit leverages the method employed by OptiClust of iteratively\nassigning sequences to OTUs to produce the highest quality OTUs\npossible, and extends this method for reference-based clustering.\nOptiClust first seeds each sequence into its own OTU as a singleton.\nThen for each sequence, OptiClust considers whether the sequence should\nmove to a different OTU or remain in its current OTU, choosing the\noption that results in a better MCC score\n[@westcott_opticlust_2017]. The MCC uses all values from a\nconfusion matrix and ranges from negative one to one, with a score of\none occurring when all sequence pairs are true positives and true\nnegatives, a score of negative one occurring when all pairs are false\npositives and false negatives, and a score of zero when there are equal\nnumbers of true and false assignments (i.e. no better than random\nguessing). Sequence pairs that are similar to each other (i.e. within\nthe distance threshold) are counted as true positives if they are\nclustered into the same OTU, and false negatives if they are not in the\nthe same OTU. Sequence pairs that are not similar to each other are true\nnegatives if they are not clustered into the same OTU, and false\npositives if they are in the same OTU. Thus, a pair of sequences is\nconsidered correctly assigned when their OTU assignment matches the OTU\ndefinition set by the distance threshold. OptiClust iterations continue\nuntil the MCC stabilizes or until a maximum number of iterations is\nreached. This process produces *de novo* OTU assignments with the most\noptimal MCC given the input sequences.\n\n::: {#fig-algorithm fig-cap=\"The OptiFit algorithm\"}\n![](/papers/optifit/paper/figures/algorithm-1.png){width=\"6.5in\" height=\"5.2in\"}\n\\justify\n\\footnotesize\nHere we present a toy example of the OptiFit algorithm fitting query\nsequences to existing OTUs, given the list of all sequence pairs that\nare within the distance threshold of 3%. Previously, 50 reference\nsequences were clustered *de novo* with OptiClust (see the OptiClust\nsupplemental text [@westcott_opticlust_2017]). Reference\nsequences A through Q (colored ) were within the distance threshold to\nat least one other reference sequence; the remaining reference sequences\nformed additional singleton OTUs (not shown). The goal of OptiFit is to\nassign the query sequences W through Z (colored ) to the reference OTUs.\nHere, there are 50 reference sequences and 4 query sequences which make\n1,431 sequence pairs, of which 23 pairs are within the 3% distance\nthreshold. Initially (step 1), OptiFit places each query sequence in its\nown OTU, resulting in 14 true positives, 9 false negatives, 0 false\npositives, and 1,408 true negatives for an MCC score of 0.78. Then, for\neach query sequence (), OptiFit determines what the new MCC score would\nbe if that sequence were moved to one of the OTUs containing at least\none other similar sequence (steps 2-4). The sequence is then moved to\nthe OTU which would result in the best MCC score. OptiFit stops\niterating over sequences once the MCC score stabilizes. In this example,\nonly one iteration over each sequence was needed. Note that sequence Z\nwas dissimilar from all other sequences and thus it remained a\nsingleton. The final MCC score is 0.91 with 20 true positives, 3 false\nnegatives, 1 false positive, and 1407 true\nnegatives.\n:::\n\nOptiFit begins where OptiClust ends, starting with a list of reference\nOTUs and their sequences, a list of query sequences to cluster to the\nreference OTUs, and the sequence pairs that are within the distance\nthreshold (e.g. 0.03) (@fig-algorithm). Initially, all query sequences are\nplaced into separate OTUs. Then, the algorithm iteratively reassigns the\nquery sequences to the reference OTUs to optimize the MCC.\nAlternatively, a sequence will remain unassigned if the MCC value is\nmaximized when the sequence is a singleton rather than clustered into a\nreference OTU. All query and reference sequence pairs are considered\nwhen calculating the MCC. This process is repeated until the MCC changes\nby no more than 0.0001 (default) or until a maximum number of iterations\nis reached (default: 100). In the closed reference mode, any query\nsequences that cannot be clustered into reference OTUs are discarded,\nand the results only contain OTUs that exist in the original reference.\nIn the open reference mode, unassigned query sequences are clustered *de\nnovo* using OptiClust to generate new OTUs. The final MCC is reported\nwith the best OTU assignments. There are two strategies for generating\nOTUs with OptiFit: 1) cluster the query sequences to reference OTUs\ngenerated by *de novo* clustering an independent database, or 2) split\nthe dataset into a reference and query fraction, cluster the reference\nsequences *de novo*, then cluster the query sequences to the reference\nOTUs.\n\n### Reference clustering with public databases\n\nTo test how OptiFit performs for reference-based clustering, we\nclustered each dataset to three databases of reference OTUs: the\nGreengenes database v13_8\\_99 [@desantis_greengenes_2006], the\nSILVA non-redundant database v132 [@quast_silva_2013], and the\nRibosomal Database Project (RDP) v16 [@cole_ribosomal_2014].\nReference OTUs for each database were created by performing *de novo*\nclustering with OptiClust at a distance threshold of 3% using the V4\nregion of each sequence (see @fig-workflow). After trimming to the V4 region,\nthe databases contained 174,979, 16,192, and 173,648 unique sequences\nand produced *de novo* MCC scores of 0.72, 0.74, and 0.73 for\nGreengenes, RDP, and SILVA, respectively. Clustering query sequences\nwith OptiFit to Greengenes and SILVA in closed reference mode performed\nsimilarly, with median MCC scores of 0.85 and 0.77 respectively, while\nthe median MCC was 0.35 when clustering to RDP (@fig-results-sum; \"db:\nGreengenes\", \"db: SILVA\", and \"db: RDP\"). For comparison, clustering\ndatasets with OptiClust produced an average MCC score of 0.86 (@fig-results-sum;\n\"*de novo*\"). This gap in OTU quality mostly disappeared when clustering\nin open reference mode, which produced median MCCs of 0.86 with\nGreengenes, 0.86 with SILVA, and 0.86 with the RDP. Thus, open reference\nOptiFit produced OTUs of very similar quality as *de novo* clustering\nwith OptiClust, and closed reference OptiFit followed closely behind as\nlong as a suitable reference database was chosen.\n\n::: {#fig-workflow fig-cap=\"The OptiFit benchmarking workflow\"}\n![](/papers/optifit/paper/figures/workflow-1.png){width=\"6.5in\" height=\"4.3in\"}\n\\justify\n\\footnotesize\nReference sequences from Greengenes, the RDP, and SILVA were\ndownloaded, preprocessed with mothur by trimming to the V4 region, and\nclustered *de novo* with OptiClust for 100 repetitions. Datasets from\nhuman, marine, mouse, and soil microbiomes were downloaded, preprocessed\nwith mothur by aligning to the SILVA V4 reference alignment, then\nclustered *de novo* with OptiClust for 100 repetitions. Individual\ndatasets were fit to reference databases with OptiFit; OptiFit was\nrepeated 100 times for each dataset and database combination. Datasets\nwere also randomly split into a reference and query fraction, and the\nquery sequences were fit to the reference sequences with OptiFit for 100\nrepetitions. The final MCC score was reported for all OptiClust and\nOptiFit repetitions.\n:::\n\nSince closed reference clustering does not cluster query sequences that\ncould not be clustered into reference OTUs, an additional measure of\nclustering performance to consider is the fraction of query sequences\nthat were able to be clustered. On average, more sequences were\nclustered with Greengenes as the reference (59%) than with SILVA (50%)\nor with the RDP (9.7%) (@fig-results-sum). This mirrored the result reported\nabove that Greengenes produced better OTUs in terms of MCC score than\neither SILVA or RDP. Note that *de novo* and open reference clustering\nmethods always cluster 100% of sequences into OTUs. The database chosen\naffects the final closed reference OTU assignments considerably in terms\nof both MCC score and fraction of query sequences that could be\nclustered into the reference OTUs.\n\n:::{#fig-results-sum fig-cap=\"OptiFit results with databases as references\"}\n![](/papers/optifit/paper/figures/results_sum-1.png){width=\"6.5in\" height=\"6.5in\"}\n\\justify\n\\footnotesize\nThe median MCC score, fraction of query sequences that mapped in\nclosed-reference clustering, and runtime in seconds from repeating each\nclustering method 100 times. Each dataset underwent three clustering\nstrategies; 1) *de novo* clustering the whole dataset using OptiClust,\n2) splitting the dataset with 50% of the sequences as a reference set\nand the other 50% as a query set, clustering the references using\nOptiClust, then clustering the query sequences to the reference OTUs\nwith OptiFit, and 3) clustering the dataset to a reference database\n(Greengenes, SILVA, or RDP). Reference-based clustering was repeated\nwith open and closed mode. For additional comparison, VSEARCH was used\nfor *de novo* and reference-based clustering against the Greengenes\ndatabase.\n:::\n\nDespite the drawbacks, closed reference methods have been used when fast\nexecution speed is required, such as when using very large datasets\n[@navas-molina_chapter_2013]. To compare performance in terms\nof speed, we repeated each OptiFit and OptiClust run 100 times and\nmeasured the execution time. Across all dataset and database\ncombinations, closed reference OptiFit outperformed both OptiClust and\nopen reference OptiFit (@fig-results-sum). For example, with the human dataset\nfit to SILVA reference OTUs, the average run times in seconds were 406.8\nfor closed reference OptiFit, 455.3 for *de novo* clustering the\ndataset, and 559.4 for open reference OptiFit. Thus, the OptiFit\nalgorithm continues the precedent that closed reference clustering\nsacrifices OTU quality for execution speed.\n\nTo compare to the reference clustering methods used by QIIME2, we\nclustered each dataset with VSEARCH against the Greengenes database of\nOTUs previously clustered at 97% sequence similarity. Each reference OTU\nfrom the Greengenes 97% database contains one reference sequence, and\nVSEARCH maps sequences to the reference based on each individual query\nsequence's similarity to the single reference sequence. In contrast,\nOptiFit accepts reference OTUs which each may contain multiple\nsequences, and the sequence similarity between all query and reference\nsequences is considered when assigning sequences to OTUs. In closed\nreference mode, OptiFit produced 27.2% higher quality OTUs than VSEARCH\nin terms of MCC score, but VSEARCH was able to cluster 24.9% more query\nsequences than OptiFit to the Greengenes reference database (@fig-results-sum).\nThis is because VSEARCH only considers the distances between each query\nsequence to the single reference sequence, while OptiFit considers the\ndistances between all pairs of reference and query sequences in an OTU.\nWhen open reference clustering, OptiFit produced higher quality OTUs\nthan VSEARCH against the Greengenes database, with median MCC scores of\n0.86 and 0.56, respectively. In terms of run time, OptiFit outperformed\nVSEARCH in both closed and open reference mode by 53.6% and 44.0% on\naverage, respectively. Thus, the more stringent OTU definition employed\nby OptiFit, which prefers the query sequence to be similar to all other\nsequences in the OTU rather than to only one sequence, resulted in fewer\nsequences being clustered to reference OTUs than when using VSEARCH, but\ncaused OptiFit to outperform VSEARCH in terms of both OTU quality and\nexecution time.\n\n### Reference clustering with split datasets\n\nWhen performing reference clustering against public databases, the\ndatabase chosen greatly affects the quality of OTUs produced. OTU\nquality may be poor when the reference database consists of sequences\nthat are too unrelated to the samples of interest, such as when samples\ncontain novel populations. While *de novo* clustering overcomes the\nquality limitations of reference clustering to databases, OTU\nassignments are not consistent when new sequences are added. Researchers\nmay wish to cluster new sequences to existing OTUs or to compare OTUs\nacross studies. To determine how well OptiFit performs for clustering\nnew sequences to existing OTUs, we employed a split dataset strategy,\nwhere each dataset was randomly split into a reference fraction and a\nquery fraction. Reference sequences were clustered *de novo* with\nOptiClust, then query sequences were clustered to the *de novo* OTUs\nwith OptiFit.\n\nFirst, we tested whether OptiFit performed as well as *de novo*\nclustering when using the split dataset strategy with half of the\nsequences selected for the reference by a simple random sample (a 50%\nsplit) (@fig-results-sum; \"self-split\"). OTU quality was similar to that from\nOptiClust regardless of mode (0.031% difference in median MCC). In\nclosed reference mode, OptiFit was able to cluster 84.9% of query\nsequences to reference OTUs with the split strategy, a great improvement\nover the average 59% of sequences clustered to the Greengenes database.\nIn terms of run time, closed and open reference OptiFit performed faster\nthan OptiClust on whole datasets by 39.6% and 36.8%, respectively.\nRandom access memory (RAM) usage was similar, with OptiFit requiring\nslightly more RAM in gigabytes than OptiClust. Open and closed reference\nOptiFit required 1.8% and 1.2% more RAM than OptiClust, respectively\n(data not shown). The split dataset strategy also performed 6.7% faster\nthan the database strategy in closed reference mode and 65.5% faster in\nopen reference mode. Thus, reference clustering with the split dataset\nstrategy creates as high quality OTUs as *de novo* clustering yet at a\nfaster run time, and fits far more query sequences than the database\nstrategy.\n\n::: {#fig-results-split fig-cap=\"OptiFit results with datasets as self-references\"}\n![](/papers/optifit/paper/figures/results_split-1.png){width=\"6.5in\" height=\"7.6in\"}\n\\justify\n\\footnotesize\nThe median MCC score, fraction of query sequences that mapped in\nclosed-reference clustering, and runtime in seconds from repeating each\nclustering method 100 times. Each dataset was split into a reference and\nquery fraction. Reference sequences were selected via a simple random\nsample, weighting sequences by relative abundance, or weighting by\nsimilarity to other sequences in the dataset. With the simple random\nsample method, dataset splitting was repeated with reference fractions\nranging from 10% to 90% of the dataset and for 100 random seeds. *De\nnovo* clustering each dataset with OptiClust is also shown for\ncomparison.\n:::\n\nWhile we initially tested this strategy using a 50% split of the data\ninto reference and query fractions, we next investigated whether there\nwas an optimal reference fraction size. To identify the best reference\nsize, reference sets with 10% to 90% of the sequences were created, with\nthe remaining sequences used for the query (@fig-results-split). OTU quality was\nremarkably consistent across reference fraction sizes. For example,\nsplitting the human dataset 100 times yielded a coefficient of variation\n(i.e. the standard deviation divided by the mean) of 0.0018 for the MCC\nscore across all fractions. Run time generally decreased as the\nreference fraction increased; for the human dataset, the median run time\nwas 364.0 seconds with 10% of sequences in the reference and 290.8\nseconds with 90% of sequences in the reference. The RAM usage was\nvirtually the same across reference fraction sizes, with a coefficient\nof variation of 0.00089 for the human dataset (data not shown). In\nclosed reference mode, the fraction of sequences that mapped increased\nas the reference size increased; for the human dataset, the median\nfraction mapped was 0.85 with 10% of sequences in the reference and 0.95\nwith 90% of sequences in the reference. These trends held for the other\ndatasets as well. Thus, the reference fraction did not affect OTU\nquality in terms of MCC score nor the memory usage, but did affect the\nrun time and the fraction of sequences that mapped during the closed\nreference clustering.\n\nAfter testing the split strategy using a simple random sample to select\nthe reference sequences, we then investigated other methods of splitting\nthe data. We tested three methods for selecting the fraction of\nsequences to be used as the reference at a size of 50%: a simple random\nsample, weighting sequences by relative abundance, and weighting by\nsimilarity to other sequences in the dataset (@fig-results-split). OTU quality in\nterms of MCC was similar across all three sampling methods (median MCC\nof 0.86). In closed-reference clustering mode, the fraction of sequences\nthat mapped were similar for simple and abundance-weighted sampling\n(median fraction mapped of 0.85 and 0.84, respectively), but worse for\nsimilarity-weighted sampling (median fraction mapped of 0.56). While\nsimple and abundance-weighted sampling produced better quality OTUs than\nsimilarity-weighted sampling, OptiFit performed faster on\nsimilarity-weighted samples with a median runtime of 103.9 seconds\ncompared to 135.4 and 134.8 seconds for simple and abundance-weighted\nsampling, respectively. Thus, employing more complicated sampling\nstrategies such as abundance-weighted and similarity-weighted sampling\ndid not confer any advantages over selecting the reference via a simple\nrandom sample, and in fact decreased OTU quality in the case of\nsimilarity-weighted sampling.\n\n## Discussion\n\nWe developed a new algorithm for clustering sequences to existing OTUs\nand have demonstrated its suitability for reference-based clustering.\nOptiFit makes the iterative method employed by OptiClust available for\ntasks where reference-based clustering is required. We have shown that\nOTU quality is similar between OptiClust and OptiFit in open reference\nmode, regardless of strategy employed. Open reference OptiFit performs\nslower than OptiClust due to the additional *de novo* clustering step,\nso users may prefer OptiClust for tasks that do not require reference\nOTUs.\n\nWhen clustering to public databases, OTU quality dropped in closed\nreference mode to different degrees depending on the database and\ndataset source, and no more than half of query sequences were able to be\nclustered into OTUs across any dataset/database combination. This may\nreflect limitations of reference databases, which are unlikely to\ncontain sequences from novel microbes. This drop in quality was most\nnotable with the RDP reference, which contained only 16,192 sequences\ncompared to 173,648 sequences in SILVA and 174,979 in Greengenes. Note\nthat Greengenes has not been updated since 2013 at the time of this\nwriting, while SILVA and the RDP are updated regularly. We recommend\nthat users who require an independent reference database opt for large\ndatabases with regular updates and good coverage of microbial diversity\nfor their environment. Since OptiClust still performs faster than open\nreference OptiFit and creates higher quality OTUs than closed reference\nOptiFit with the database strategy, we recommend using OptiClust rather\nthan clustering to a database whenever consistent OTUs are not required.\n\nThe OptiClust and OptiFit algorithms produced higher quality OTUs than\nVSEARCH in open reference, closed reference, or *de novo* modes.\nHowever, VSEARCH was able to cluster more sequences to OTUs than OptiFit\nin closed reference mode. While both OptiFit and VSEARCH use a distance\nor similarity threshold for determining how to cluster sequences into\nOTUs, VSEARCH is more permissive than OptiFit regardless of mode. The\nOptiFit and OptiClust algorithms use all of the sequences to define an\nOTU, preferring that all pairs of sequences (including reference and\nquery sequences) in an OTU are within the distance threshold in order to\nmaximize the MCC. In contrast, VSEARCH only requires each query sequence\nto be similar to the single centroid sequence that seeded the OTU, thus\nallowing pairs of query sequences to be less similar to each other than\nthe threshold specified. Because of this, VSEARCH sacrifices OTU quality\nby allowing more dissimilar sequences to be clustered into the same\nOTUs.\n\nWhen clustering with the split dataset strategy, OTU quality was\nremarkably similar when reference sequences were selected by a simple\nrandom sample or weighted by abundance, but quality was slightly worse\nwhen sequences were weighted by similarity. We recommend using a simple\nrandom sample since the more sophisticated reference selection methods\ndo not offer any benefit. The similarity in OTU quality between\nOptiClust and OptiFit with this strategy demonstrates the suitability of\nusing OptiFit to cluster sequences to existing OTUs, such as when\ncomparing OTUs across studies. However, when consistent OTUs are not\nrequired, we recommend using OptiClust for *de novo* clustering over the\nsplit strategy with OptiFit since OptiClust is simpler to execute but\nperforms similarly in terms of both run time and OTU quality.\n\nUnlike existing reference-based methods that cluster query sequences to\na single centroid sequence in each reference OTU, OptiFit considers all\nsequences in each reference OTU when clustering query sequences,\nresulting in OTUs of a similar high quality as those produced by the *de\nnovo* OptiClust algorithm. Potential applications include clustering\nsequences to reference databases, comparing taxonomic composition of\nmicrobiomes across different studies, or using OTU-based machine\nlearning models to make predictions on new data. OptiFit fills the\nmissing option for clustering query sequences to existing OTUs that does\nnot sacrifice OTU quality for consistency of OTU assignments.\n\n## Materials and Methods\n\n### Data processing steps\n\nWe downloaded 16S rRNA gene amplicon sequences from four published\ndatasets isolated from soil [@johnston_metagenomics_2016],\nmarine [@henson_artificial_2016], mouse gut\n[@schloss_stabilization_2012], and human gut\n[@baxter_microbiota-based_2016] samples. These datasets\ncontain sequences from the V4 region of the 16S rRNA gene and represent\na selection of the broad types of natural communities that microbial\necologists study. We processed the raw sequences using mothur according\nto the Schloss Lab MiSeq SOP [@schloss_miseq_nodate] and\naccompanying study by Kozich *et al.*\n[@kozich_development_2013]. These steps included trimming and\nfiltering for quality, aligning to the SILVA reference alignment\n[@quast_silva_2013], discarding sequences that aligned outside\nthe V4 region, removing chimeric reads with UCHIME\n[@edgar_uchime_2011], and calculating distances between all\npairs of sequences within each dataset prior to clustering.\n\n### Reference database clustering\n\nTo generate reference OTUs from public databases, we downloaded\nsequences from the Greengenes database (v13_8\\_99)\n[@desantis_greengenes_2006], SILVA non-redundant database\n(v132) [@quast_silva_2013], and the Ribosomal Database Project\n(v16) [@cole_ribosomal_2014]. These sequences were processed\nusing the same steps outlined above followed by clustering sequences\ninto *de novo* OTUs with OptiClust. Processed reads from each of the\nfour datasets were clustered with OptiFit to the reference OTUs\ngenerated from each of the three databases. When reference clustering\nwith VSEARCH, processed datasets were clustered directly to the\nunprocessed Greengenes 97% OTU reference alignment, since this method is\nhow VSEARCH is typically used by the QIIME2 software for reference-based\nclustering [@noauthor_clustering_nodate],\n[@bolyen_reproducible_2019].\n\n### Split dataset clustering\n\nFor each dataset, half of the sequences were selected to be clustered\n*de novo* into reference OTUs with OptiClust. We used three methods for\nselecting the subset of sequences to be used as the reference: a simple\nrandom sample, weighting sequences by relative abundance, and weighting\nby similarity to other sequences in the dataset. Dataset splitting was\nrepeated with 100 random seeds. With the simple random sampling method,\ndataset splitting was also repeated with reference fractions ranging\nfrom 10% to 90% of the dataset. For each dataset split, the remaining\nquery sequences were clustered into the reference OTUs with OptiFit.\n\n### Benchmarking\n\nOptiClust and OptiFit randomize the order of query sequences prior to\nclustering and employ a random number generator to break ties when OTU\nassignments are of equal quality. As a result, they produce slightly\ndifferent OTU assignments when repeated with different random seeds. To\ncapture any variation in OTU quality or execution time, clustering was\nrepeated with 100 random seeds for each combination of parameters and\ninput datasets. We used the benchmark feature provided by Snakemake to\nmeasure the run time of every clustering job. We calculated the MCC on\neach set of OTUs to quantify the quality of clustering, as described by\nWestcott *et al.* [@westcott_opticlust_2017].\n\n### Data and code availability\n\nWe implemented the analysis workflow in Snakemake\n[@koster_snakemake_2012] and wrote scripts in R\n[@r_core_team_r_2023], Python\n[@van_rossum_python_2009], and GNU bash\n[@noauthor_bash_nodate]. Software used includes mothur v1.47.0\n[@schloss_introducing_2009], VSEARCH v2.15.2\n[@rognes_vsearch_2016], the tidyverse metapackage\n[@wickham_welcome_2019], R Markdown [@xie_r_2018],\nggraph [@pederson_ggraph_2021], ggtext\n[@wilke_ggtext_2020], numpy [@harris_array_2020],\nthe SRA toolkit [@noauthor_sra-tools_nodate], and conda.\nThe complete workflow and supporting files required to reproduce this manuscript\nare available at <https://github.com/SchlossLab/Sovacool_OptiFit_mSphere_2022>.\n\n## Acknowledgements\n\nWe thank members of the Schloss Lab for their feedback on the figures.\n\nKLS received support from the NIH Training Program in Bioinformatics\n(T32 GM070449). Salary support for PDS came from NIH grants R01CA215574\nand U01AI124255. The funders had no role in study design, data\ncollection and interpretation, or the decision to submit the work for\npublication.\n\n## Author Contributions\n\nKLS wrote the analysis code, evaluated the algorithm, and wrote the\noriginal draft of the manuscript. SLW designed and implemented the\nOptiFit algorithm and assisted in debugging the analysis code. MBM and\nGAD contributed analysis code. PDS conceived the study, supervised the\nproject, and assisted in debugging the analysis code. All authors\nreviewed and edited the manuscript.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}